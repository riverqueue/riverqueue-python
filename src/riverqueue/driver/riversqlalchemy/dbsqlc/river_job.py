# Code generated by sqlc. DO NOT EDIT.
# versions:
#   sqlc v1.27.0
# source: river_job.sql
import dataclasses
import datetime
from typing import Any, AsyncIterator, Iterator, List, Optional

import sqlalchemy
import sqlalchemy.ext.asyncio

from . import models


JOB_GET_ALL = """-- name: job_get_all \\:many
SELECT id, args, attempt, attempted_at, attempted_by, created_at, errors, finalized_at, kind, max_attempts, metadata, priority, queue, state, scheduled_at, tags, unique_key, unique_states
FROM river_job
"""


JOB_GET_BY_ID = """-- name: job_get_by_id \\:one
SELECT id, args, attempt, attempted_at, attempted_by, created_at, errors, finalized_at, kind, max_attempts, metadata, priority, queue, state, scheduled_at, tags, unique_key, unique_states
FROM river_job
WHERE id = :p1
"""


JOB_INSERT_FAST_MANY = """-- name: job_insert_fast_many \\:many
INSERT INTO river_job(
    args,
    kind,
    max_attempts,
    metadata,
    priority,
    queue,
    scheduled_at,
    state,
    tags,
    unique_key,
    unique_states
) SELECT
    unnest(:p1\\:\\:jsonb[]),
    unnest(:p2\\:\\:text[]),
    unnest(:p3\\:\\:smallint[]),
    unnest(:p4\\:\\:jsonb[]),
    unnest(:p5\\:\\:smallint[]),
    unnest(:p6\\:\\:text[]),
    unnest(:p7\\:\\:timestamptz[]),
    unnest(:p8\\:\\:river_job_state[]),
    -- Unnest on a multi-dimensional array will fully flatten the array, so we
    -- encode the tag list as a comma-separated string and split it in the
    -- query.
    string_to_array(unnest(:p9\\:\\:text[]), ','),

    unnest(:p10\\:\\:bytea[]),
    -- Strings of bits are used for the input type here to make sqlalchemy play nicely with bit(8)\\:
    unnest(:p11\\:\\:text[])\\:\\:bit(8)

ON CONFLICT (unique_key)
    WHERE unique_key IS NOT NULL
      AND unique_states IS NOT NULL
      AND river_job_state_in_bitmask(unique_states, state)
    -- Something needs to be updated for a row to be returned on a conflict.
    DO UPDATE SET kind = EXCLUDED.kind
RETURNING river_job.id, river_job.args, river_job.attempt, river_job.attempted_at, river_job.attempted_by, river_job.created_at, river_job.errors, river_job.finalized_at, river_job.kind, river_job.max_attempts, river_job.metadata, river_job.priority, river_job.queue, river_job.state, river_job.scheduled_at, river_job.tags, river_job.unique_key, river_job.unique_states, (xmax != 0) AS unique_skipped_as_duplicate
"""


@dataclasses.dataclass()
class JobInsertFastManyParams:
    args: List[Any]
    kind: List[str]
    max_attempts: List[int]
    metadata: List[Any]
    priority: List[int]
    queue: List[str]
    scheduled_at: List[datetime.datetime]
    state: List[models.RiverJobState]
    tags: List[str]
    unique_key: List[memoryview]
    unique_states: List[str]


@dataclasses.dataclass()
class JobInsertFastManyRow:
    id: int
    args: Any
    attempt: int
    attempted_at: Optional[datetime.datetime]
    attempted_by: Optional[List[str]]
    created_at: datetime.datetime
    errors: Optional[List[Any]]
    finalized_at: Optional[datetime.datetime]
    kind: str
    max_attempts: int
    metadata: Any
    priority: int
    queue: str
    state: models.RiverJobState
    scheduled_at: datetime.datetime
    tags: List[str]
    unique_key: Optional[memoryview]
    unique_states: Optional[Any]
    unique_skipped_as_duplicate: bool


JOB_INSERT_FULL = """-- name: job_insert_full \\:one
INSERT INTO river_job(
    args,
    attempt,
    attempted_at,
    created_at,
    errors,
    finalized_at,
    kind,
    max_attempts,
    metadata,
    priority,
    queue,
    scheduled_at,
    state,
    tags,
    unique_key
) VALUES (
    :p1\\:\\:jsonb,
    coalesce(:p2\\:\\:smallint, 0),
    :p3,
    coalesce(:p4\\:\\:timestamptz, now()),
    :p5\\:\\:jsonb[],
    :p6,
    :p7\\:\\:text,
    :p8\\:\\:smallint,
    coalesce(:p9\\:\\:jsonb, '{}'),
    :p10\\:\\:smallint,
    :p11\\:\\:text,
    coalesce(:p12\\:\\:timestamptz, now()),
    :p13\\:\\:river_job_state,
    coalesce(:p14\\:\\:varchar(255)[], '{}'),
    :p15
) RETURNING id, args, attempt, attempted_at, attempted_by, created_at, errors, finalized_at, kind, max_attempts, metadata, priority, queue, state, scheduled_at, tags, unique_key, unique_states
"""


@dataclasses.dataclass()
class JobInsertFullParams:
    args: Any
    attempt: int
    attempted_at: Optional[datetime.datetime]
    created_at: Optional[datetime.datetime]
    errors: List[Any]
    finalized_at: Optional[datetime.datetime]
    kind: str
    max_attempts: int
    metadata: Any
    priority: int
    queue: str
    scheduled_at: Optional[datetime.datetime]
    state: models.RiverJobState
    tags: List[str]
    unique_key: Optional[memoryview]


class Querier:
    def __init__(self, conn: sqlalchemy.engine.Connection):
        self._conn = conn

    def job_get_all(self) -> Iterator[models.RiverJob]:
        result = self._conn.execute(sqlalchemy.text(JOB_GET_ALL))
        for row in result:
            yield models.RiverJob(
                id=row[0],
                args=row[1],
                attempt=row[2],
                attempted_at=row[3],
                attempted_by=row[4],
                created_at=row[5],
                errors=row[6],
                finalized_at=row[7],
                kind=row[8],
                max_attempts=row[9],
                metadata=row[10],
                priority=row[11],
                queue=row[12],
                state=row[13],
                scheduled_at=row[14],
                tags=row[15],
                unique_key=row[16],
                unique_states=row[17],
            )

    def job_get_by_id(self, *, id: int) -> Optional[models.RiverJob]:
        row = self._conn.execute(sqlalchemy.text(JOB_GET_BY_ID), {"p1": id}).first()
        if row is None:
            return None
        return models.RiverJob(
            id=row[0],
            args=row[1],
            attempt=row[2],
            attempted_at=row[3],
            attempted_by=row[4],
            created_at=row[5],
            errors=row[6],
            finalized_at=row[7],
            kind=row[8],
            max_attempts=row[9],
            metadata=row[10],
            priority=row[11],
            queue=row[12],
            state=row[13],
            scheduled_at=row[14],
            tags=row[15],
            unique_key=row[16],
            unique_states=row[17],
        )

    def job_insert_fast_many(self, arg: JobInsertFastManyParams) -> Iterator[JobInsertFastManyRow]:
        result = self._conn.execute(sqlalchemy.text(JOB_INSERT_FAST_MANY), {
            "p1": arg.args,
            "p2": arg.kind,
            "p3": arg.max_attempts,
            "p4": arg.metadata,
            "p5": arg.priority,
            "p6": arg.queue,
            "p7": arg.scheduled_at,
            "p8": arg.state,
            "p9": arg.tags,
            "p10": arg.unique_key,
            "p11": arg.unique_states,
        })
        for row in result:
            yield JobInsertFastManyRow(
                id=row[0],
                args=row[1],
                attempt=row[2],
                attempted_at=row[3],
                attempted_by=row[4],
                created_at=row[5],
                errors=row[6],
                finalized_at=row[7],
                kind=row[8],
                max_attempts=row[9],
                metadata=row[10],
                priority=row[11],
                queue=row[12],
                state=row[13],
                scheduled_at=row[14],
                tags=row[15],
                unique_key=row[16],
                unique_states=row[17],
                unique_skipped_as_duplicate=row[18],
            )

    def job_insert_full(self, arg: JobInsertFullParams) -> Optional[models.RiverJob]:
        row = self._conn.execute(sqlalchemy.text(JOB_INSERT_FULL), {
            "p1": arg.args,
            "p2": arg.attempt,
            "p3": arg.attempted_at,
            "p4": arg.created_at,
            "p5": arg.errors,
            "p6": arg.finalized_at,
            "p7": arg.kind,
            "p8": arg.max_attempts,
            "p9": arg.metadata,
            "p10": arg.priority,
            "p11": arg.queue,
            "p12": arg.scheduled_at,
            "p13": arg.state,
            "p14": arg.tags,
            "p15": arg.unique_key,
        }).first()
        if row is None:
            return None
        return models.RiverJob(
            id=row[0],
            args=row[1],
            attempt=row[2],
            attempted_at=row[3],
            attempted_by=row[4],
            created_at=row[5],
            errors=row[6],
            finalized_at=row[7],
            kind=row[8],
            max_attempts=row[9],
            metadata=row[10],
            priority=row[11],
            queue=row[12],
            state=row[13],
            scheduled_at=row[14],
            tags=row[15],
            unique_key=row[16],
            unique_states=row[17],
        )


class AsyncQuerier:
    def __init__(self, conn: sqlalchemy.ext.asyncio.AsyncConnection):
        self._conn = conn

    async def job_get_all(self) -> AsyncIterator[models.RiverJob]:
        result = await self._conn.stream(sqlalchemy.text(JOB_GET_ALL))
        async for row in result:
            yield models.RiverJob(
                id=row[0],
                args=row[1],
                attempt=row[2],
                attempted_at=row[3],
                attempted_by=row[4],
                created_at=row[5],
                errors=row[6],
                finalized_at=row[7],
                kind=row[8],
                max_attempts=row[9],
                metadata=row[10],
                priority=row[11],
                queue=row[12],
                state=row[13],
                scheduled_at=row[14],
                tags=row[15],
                unique_key=row[16],
                unique_states=row[17],
            )

    async def job_get_by_id(self, *, id: int) -> Optional[models.RiverJob]:
        row = (await self._conn.execute(sqlalchemy.text(JOB_GET_BY_ID), {"p1": id})).first()
        if row is None:
            return None
        return models.RiverJob(
            id=row[0],
            args=row[1],
            attempt=row[2],
            attempted_at=row[3],
            attempted_by=row[4],
            created_at=row[5],
            errors=row[6],
            finalized_at=row[7],
            kind=row[8],
            max_attempts=row[9],
            metadata=row[10],
            priority=row[11],
            queue=row[12],
            state=row[13],
            scheduled_at=row[14],
            tags=row[15],
            unique_key=row[16],
            unique_states=row[17],
        )

    async def job_insert_fast_many(self, arg: JobInsertFastManyParams) -> AsyncIterator[JobInsertFastManyRow]:
        result = await self._conn.stream(sqlalchemy.text(JOB_INSERT_FAST_MANY), {
            "p1": arg.args,
            "p2": arg.kind,
            "p3": arg.max_attempts,
            "p4": arg.metadata,
            "p5": arg.priority,
            "p6": arg.queue,
            "p7": arg.scheduled_at,
            "p8": arg.state,
            "p9": arg.tags,
            "p10": arg.unique_key,
            "p11": arg.unique_states,
        })
        async for row in result:
            yield JobInsertFastManyRow(
                id=row[0],
                args=row[1],
                attempt=row[2],
                attempted_at=row[3],
                attempted_by=row[4],
                created_at=row[5],
                errors=row[6],
                finalized_at=row[7],
                kind=row[8],
                max_attempts=row[9],
                metadata=row[10],
                priority=row[11],
                queue=row[12],
                state=row[13],
                scheduled_at=row[14],
                tags=row[15],
                unique_key=row[16],
                unique_states=row[17],
                unique_skipped_as_duplicate=row[18],
            )

    async def job_insert_full(self, arg: JobInsertFullParams) -> Optional[models.RiverJob]:
        row = (await self._conn.execute(sqlalchemy.text(JOB_INSERT_FULL), {
            "p1": arg.args,
            "p2": arg.attempt,
            "p3": arg.attempted_at,
            "p4": arg.created_at,
            "p5": arg.errors,
            "p6": arg.finalized_at,
            "p7": arg.kind,
            "p8": arg.max_attempts,
            "p9": arg.metadata,
            "p10": arg.priority,
            "p11": arg.queue,
            "p12": arg.scheduled_at,
            "p13": arg.state,
            "p14": arg.tags,
            "p15": arg.unique_key,
        })).first()
        if row is None:
            return None
        return models.RiverJob(
            id=row[0],
            args=row[1],
            attempt=row[2],
            attempted_at=row[3],
            attempted_by=row[4],
            created_at=row[5],
            errors=row[6],
            finalized_at=row[7],
            kind=row[8],
            max_attempts=row[9],
            metadata=row[10],
            priority=row[11],
            queue=row[12],
            state=row[13],
            scheduled_at=row[14],
            tags=row[15],
            unique_key=row[16],
            unique_states=row[17],
        )
